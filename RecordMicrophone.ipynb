{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Structures.py:91: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  bilstm = merge([lstm_fwd, lstm_bwd], name='bilstm', mode='concat')\n",
      "/Users/julian/anaconda3/envs/Python27/lib/python2.7/site-packages/keras/legacy/layers.py:464: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "Structures.py:100: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  sent_representation = merge([attention,drop_out], dot_axes=1, mode='dot')\n",
      "Structures.py:105: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=[<tf.Tenso...)`\n",
      "  model = Model(input=[encoding_input], output=output)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import Structures\n",
    "import EmotionExtractor\n",
    "\n",
    "\n",
    "em = EmotionExtractor.EmotionExtractor('baseline.npy', 'baseline_mean_sd.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import byteorder\n",
    "from array import array\n",
    "from struct import pack\n",
    "import time\n",
    "import threading\n",
    "from Queue import Queue\n",
    "import numpy as np\n",
    "import pyaudio\n",
    "import wave\n",
    "import os\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 500\n",
    "CHUNK_SIZE = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "RATE = 8000\n",
    "RECORD_SECONDS = 3\n",
    "WAVE_OUTPUT_FILENAME_EXTENSION = 0\n",
    "WAVE_OUTPUT_FILENAME = \"output\"\n",
    "\n",
    "q = Queue()\n",
    "lock = threading.Lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def is_silent(snd_data):\n",
    "    \"Returns 'True' if below the 'silent' threshold\"\n",
    "    return max(snd_data) < THRESHOLD\n",
    "\n",
    "def normalize(snd_data):\n",
    "    \"Average the volume out\"\n",
    "    MAXIMUM = 16384\n",
    "    times = float(MAXIMUM)/max(abs(i) for i in snd_data)\n",
    "\n",
    "    r = array('h')\n",
    "    for i in snd_data:\n",
    "        r.append(int(i*times))\n",
    "    return r\n",
    "\n",
    "def trim(snd_data):\n",
    "    \"Trim the blank spots at the start and end\"\n",
    "    def _trim(snd_data):\n",
    "        snd_started = False\n",
    "        r = array('h')\n",
    "\n",
    "        for i in snd_data:\n",
    "            if not snd_started and abs(i)>THRESHOLD:\n",
    "                snd_started = True\n",
    "                r.append(i)\n",
    "\n",
    "            elif snd_started:\n",
    "                r.append(i)\n",
    "        return r\n",
    "\n",
    "    # Trim to the left\n",
    "    snd_data = _trim(snd_data)\n",
    "\n",
    "    # Trim to the right\n",
    "    snd_data.reverse()\n",
    "    snd_data = _trim(snd_data)\n",
    "    snd_data.reverse()\n",
    "    return snd_data\n",
    "\n",
    "def add_silence(snd_data, seconds):\n",
    "    \"Add silence to the start and end of 'snd_data' of length 'seconds' (float)\"\n",
    "    r = array('h', [0 for i in range(int(seconds*RATE))])\n",
    "    r.extend(snd_data)\n",
    "    r.extend([0 for i in range(int(seconds*RATE))])\n",
    "    return r\n",
    "\n",
    "def record():\n",
    "    \"\"\"\n",
    "    Record a word or words from the microphone and \n",
    "    return the data as an array of signed shorts.\n",
    "\n",
    "    Normalizes the audio, trims silence from the \n",
    "    start and end.\n",
    "    \"\"\"\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT, channels=1, rate=RATE, input=True, output=True, frames_per_buffer=CHUNK_SIZE)\n",
    "\n",
    "    num_silent = 0\n",
    "    snd_started = False\n",
    "\n",
    "    r = array('h')\n",
    "    count = 0\n",
    "    for i in range(0, int(RATE / CHUNK_SIZE * RECORD_SECONDS)):\n",
    "        count +=1\n",
    "        # little endian, signed short\n",
    "        snd_data = array('h', stream.read(CHUNK_SIZE))\n",
    "        if byteorder == 'big':\n",
    "            snd_data.byteswap()\n",
    "        r.extend(snd_data)\n",
    "\n",
    "        #print('\\r%08d' % count)\n",
    "        #silent = is_silent(snd_data)\n",
    "\n",
    "        #if silent and snd_started:\n",
    "            #num_silent += 1\n",
    "        #elif not silent and not snd_started:\n",
    "            #snd_started = True\n",
    "\n",
    "    sample_width = p.get_sample_size(FORMAT)\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    r = normalize(r)\n",
    "    #r = trim(r)\n",
    "    #r = add_silence(r, 0.5)\n",
    "    return sample_width, r\n",
    "\n",
    "def record_to_file():\n",
    "    with lock:\n",
    "        WAVE_OUTPUT_FILENAME_EXTENSION = 0\n",
    "        WAVE_OUTPUT_FILENAME = \"rec\"\n",
    "        d= True\n",
    "        \n",
    "        ts = time.time()\n",
    "        EXPORT_FOLDER = \"RECORDINGS_\" + str(ts).split(\".\")[0]\n",
    "        if not os.path.exists(EXPORT_FOLDER):\n",
    "            os.makedirs(EXPORT_FOLDER)\n",
    "        \n",
    "        # the sound of each 3 seconds intervall\n",
    "        # they get combined later to a 9 seconds total interval\n",
    "        first_recording = None\n",
    "        second_recording = None\n",
    "        third_recording = None\n",
    "        while d:\n",
    "            q.join()\n",
    "            print('Recording')\n",
    "            sample_width, data = record()\n",
    "            # if there was no recording done so far\n",
    "            # store the first 3 seconds in the first recording\n",
    "            if first_recording == None:\n",
    "                first_recording = data\n",
    "            # if there was only one recording done so far\n",
    "            # store the next recording in the second recording\n",
    "            elif second_recording == None:\n",
    "                second_recording = data\n",
    "            # for every recording coming after the first 2 times 3 seconds\n",
    "            # store the recording in the third recording\n",
    "            else:\n",
    "                third_recording = data\n",
    "                    \n",
    "                # append all the recordings to a 9 seconds interval\n",
    "                data = first_recording\n",
    "                data = np.append(data, second_recording)\n",
    "                data = np.append(data, third_recording)\n",
    "                # pack the data properly to be exported as a wave file\n",
    "                data = pack('<' + ('h'*len(data)), *data)\n",
    "                \n",
    "                print('Saving........')\n",
    "                wf = wave.open(EXPORT_FOLDER + \"/\" + WAVE_OUTPUT_FILENAME + \"_\" + str(WAVE_OUTPUT_FILENAME_EXTENSION) + \".wav\", 'wb')\n",
    "                wf.setnchannels(1)\n",
    "                wf.setsampwidth(sample_width)\n",
    "                wf.setframerate(RATE)\n",
    "                wf.writeframes(data)\n",
    "                wf.close()\n",
    "                \n",
    "                # \n",
    "                song = AudioSegment.from_wav(EXPORT_FOLDER + \"/\" + WAVE_OUTPUT_FILENAME + \"_\" + str(WAVE_OUTPUT_FILENAME_EXTENSION) + \".wav\")\n",
    "                song.export(EXPORT_FOLDER + \"/\" + WAVE_OUTPUT_FILENAME + \"_\" + str(WAVE_OUTPUT_FILENAME_EXTENSION) + \".mp3\", format=\"mp3\")\n",
    "                song = AudioSegment.from_mp3(EXPORT_FOLDER + \"/\" + WAVE_OUTPUT_FILENAME + \"_\" + str(WAVE_OUTPUT_FILENAME_EXTENSION) + \".mp3\")\n",
    "                print(\"song\")\n",
    "                print(song.frame_rate)\n",
    "                print(song.sample_width)\n",
    "                result =  em.split_single_song(song)\n",
    "#                 result[\"filename\"] = i\n",
    "\n",
    "                #dict_to_append = result.to_dict('record')\n",
    "                \n",
    "                #to_json.append(dict_to_append[0])\n",
    "                #print result.to_dict('list')\n",
    "                print(\"result\")\n",
    "                print result.to_dict('record')\n",
    "                #print result_all.to_json()\n",
    "                \n",
    "                # increase the name counter of the filename\n",
    "                WAVE_OUTPUT_FILENAME_EXTENSION += 1\n",
    "\n",
    "                # shift the recordings and delete the last recording\n",
    "                # shift the second recording to be the first now\n",
    "                first_recording = None\n",
    "                first_recording = second_recording\n",
    "                # shift the third recording to be the second now\n",
    "                second_recording = None\n",
    "                second_recording = third_recording\n",
    "                # empty the third recording so a new recording can be made\n",
    "                third_recording = None\n",
    "                \n",
    "                d = False\n",
    "            \n",
    "            # Exit the loop with enter\n",
    "            try:\n",
    "                if q.get(timeout = 0) == 1:\n",
    "                    d = False\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        print('Task Completing')\n",
    "        q.task_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press Enter to stop Recording\n",
      "Recording\n",
      "Recording\n",
      "Recording\n",
      "Saving........\n",
      "song\n",
      "8000\n",
      "8000\n",
      "8000\n",
      "8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/julian/anaconda3/envs/Python27/lib/python2.7/threading.py\", line 801, in __bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/julian/anaconda3/envs/Python27/lib/python2.7/threading.py\", line 754, in run\n",
      "    self.__target(*self.__args, **self.__kwargs)\n",
      "  File \"<ipython-input-4-af1297fc49a2>\", line 142, in record_to_file\n",
      "    result =  em.split_single_song(song)\n",
      "  File \"EmotionExtractor.py\", line 126, in split_single_song\n",
      "    prediction = self.my_attention_network.predict(np.array([convers]))[0]\n",
      "  File \"/Users/julian/anaconda3/envs/Python27/lib/python2.7/site-packages/keras/engine/training.py\", line 1839, in predict\n",
      "    self._make_predict_function()\n",
      "  File \"/Users/julian/anaconda3/envs/Python27/lib/python2.7/site-packages/keras/engine/training.py\", line 1029, in _make_predict_function\n",
      "    **kwargs)\n",
      "  File \"/Users/julian/anaconda3/envs/Python27/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 2499, in function\n",
      "    return Function(inputs, outputs, updates=updates, **kwargs)\n",
      "  File \"/Users/julian/anaconda3/envs/Python27/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 2442, in __init__\n",
      "    with tf.control_dependencies(self.outputs):\n",
      "  File \"/Users/julian/anaconda3/envs/Python27/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3595, in control_dependencies\n",
      "    return get_default_graph().control_dependencies(control_inputs)\n",
      "  File \"/Users/julian/anaconda3/envs/Python27/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3324, in control_dependencies\n",
      "    c = self.as_graph_element(c)\n",
      "  File \"/Users/julian/anaconda3/envs/Python27/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2414, in as_graph_element\n",
      "    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)\n",
      "  File \"/Users/julian/anaconda3/envs/Python27/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2493, in _as_graph_element_locked\n",
      "    raise ValueError(\"Tensor %s is not an element of this graph.\" % obj)\n",
      "ValueError: Tensor Tensor(\"dense_3/Softmax:0\", shape=(?, 7), dtype=float32) is not an element of this graph.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print('Press Enter to stop Recording')\n",
    "    t = threading.Thread(target=record_to_file)\n",
    "    t.daemon=True\n",
    "    t.start()\n",
    "    input()\n",
    "    q.put(1)\n",
    "    q.join()\n",
    "    print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

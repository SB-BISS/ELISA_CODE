{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "import subprocess\n",
    "import shlex\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the sentiment (pos, neg) when given a string.\n",
    "def RateSentiment(sentiString):\n",
    "    #open a subprocess using shlex to get the command line string into the correct args list format\n",
    "    #p = subprocess.Popen(shlex.split(\"java -jar SentiStrengthCom.jar stdin sentidata C:/Python27/sentistrength/\"),stdin=subprocess.PIPE,stdout=subprocess.PIPE,stderr=subprocess.PIPE)\n",
    "    p = subprocess.Popen(shlex.split(\"java -jar C:/Python27/SentiStrengthCom.jar stdin sentidata C:/Python27/sentistrength/\"),stdin=subprocess.PIPE,stdout=subprocess.PIPE,stderr=subprocess.PIPE)\n",
    "    #communicate via stdin the string to be rated. Note that all spaces are replaced with +\n",
    "    stdout_text, stderr_text = p.communicate(sentiString.replace(\" \",\"+\"))\n",
    "    #remove the tab spacing between the positive and negative ratings. e.g. 1    -5 -> 1-5\n",
    "    stdout_text = stdout_text.rstrip().replace(\"\\t\",\"\")\n",
    "    return stdout_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updates a JSON file\n",
    "def updateJSON(newdata, outFilePath):\n",
    "    data = json.load(open(outFilePath))\n",
    "    if(len(data[\"fragments\"])==0):\n",
    "        with open(outFilePath, 'w') as outfile:\n",
    "            json.dump(newdata, outfile, sort_keys=True, indent=4)\n",
    "            print \"\\n\\n\\ndata file created: \" + outFilePath\n",
    "    else:\n",
    "        for v in newdata[\"fragments\"]:\n",
    "            data[\"fragments\"].append(v)\n",
    "        with open(outFilePath, 'w') as outfile:\n",
    "            json.dump(data, outfile, sort_keys=True, indent=4)\n",
    "            print \"\\n\\n\\n==================data file updated: \" + outFilePath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the sentences in JSONs, applies sentiment analysis and updates the JSON objects.\n",
    "def getSentencesFromJSON(jsonFilePath, company):\n",
    "    data = json.load(open(jsonFilePath))\n",
    "    pprint(data[\"fragments\"][0])\n",
    "    QnAPartCounter = 0\n",
    "    QuestionCounter = 0\n",
    "    AnswerCounter = 0\n",
    "    for v in data[\"fragments\"]:\n",
    "        #print v['lines'][0]\n",
    "        sentence = v['lines'][0]\n",
    "        if len(sentence)>0:\n",
    "            pos, neg = RateSentiment(sentence).split('-')\n",
    "        else:\n",
    "            pos = '0'\n",
    "            neg = '0'\n",
    "        print sentence + \",\" + pos + \",\" + neg\n",
    "        v['positive_sentiment'] = pos\n",
    "        v['negative_sentiment'] = neg\n",
    "        v['sentenceMP3'] = jsonFilePath\n",
    "        v['company'] = company\n",
    "        yearquart=jsonFilePath\n",
    "        if 'qna' in yearquart:\n",
    "            year = yearquart[yearquart.find('qna')-3:yearquart.find('qna')]\n",
    "        else:\n",
    "            year = yearquart[yearquart.find('call')-3:yearquart.find('call')]\n",
    "        v['year'] = '20' + year[1:]\n",
    "        v['quartile'] = year[0]\n",
    "        v['yearQuartile'] = '20' + year[1:] + year[0]\n",
    "        \n",
    "        if \"O: \" in sentence:\n",
    "            QnAPartCounter += 1\n",
    "            QuestionCounter = 0\n",
    "            AnswerCounter = 0\n",
    "        if \"Q: \" in sentence:\n",
    "            QuestionCounter += 1\n",
    "            AnswerCounter = 0\n",
    "        if \"A: \" in sentence:\n",
    "            AnswerCounter += 1\n",
    "        v[\"question_id\"] = company + \".\" + '20' + year[1:] + year[0] + \".\" + str(QnAPartCounter) + \".\" + str(QuestionCounter) + \".\" + str(AnswerCounter)\n",
    "    updateJSON(data, \"data_sentiment_deneme.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\SES\\sesq416qna\\sesq416qna.json\n",
      "{u'begin': u'0.000',\n",
      " u'children': [],\n",
      " u'end': u'4.920',\n",
      " u'id': u'f000001',\n",
      " u'language': u'eng',\n",
      " u'lines': [u'Q: Yeah.']}\n",
      "Q: Yeah.,1,1\n",
      "So, Wilton, there's no correlation between what Charlie Ergen says and maturity on our bonds, so it's the first point I'd like to make.,2,1\n",
      "And just to remind you of our financial framework and our treasury road map, we've a very consistent treasury road map.,2,1\n",
      "We work off of three or four principles which will continue to prevail.,1,1\n",
      "One is we're a long-term business and, therefore, we've worked over the last two to three years to increase the overall maturity of our senior debt such that it's now around eight years.,1,1\n",
      "We did that but at the same time reducing the average cost of our debt towards the 3.87% today.,1,1\n",
      "Secondly, we keep a good mix between dollar-denominated debt and euro-denominated debt so that we match this with our dollar-denominated EBITDA and euro-denominated EBITDA.,3,1\n",
      "And you'll see, when you look our balance sheet, that that's worked very much to our favor with a very important addition of about 0.25 billion to shareholders' equity, so good FX management.,3,1\n",
      "And then the last point, as I mentioned earlier, is we keep from maturities on a steady state so that we have, at all times, also very good liquidity, some very good facilities we have in place and a steady state maturity.,4,1\n",
      "And there's no change in any of that strategy.,1,1\n",
      "Richard Whiteing I think on that note, that's probably a good time to close out.,3,1\n",
      "So, thank you, everyone, for, again, joining us in the room and also those listening via the webcast and the conference call.,2,1\n",
      "As always, myself and the team remain at your disposal should you need any follow up later.,1,2\n",
      "Thank you very much.,2,1\n",
      "\n",
      "\n",
      "\n",
      "data file created: data_sentiment_deneme.json\n"
     ]
    }
   ],
   "source": [
    "# Walkthrough the files in the folder and subfolders\n",
    "def pywalkerMP3(path, company):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file_ in files:\n",
    "            if(\"qna.json\" in file_):\n",
    "                filename = os.path.join(root, file_) \n",
    "                print filename\n",
    "                getSentencesFromJSON(filename, company)\n",
    "\n",
    "# ENTRANCE METHOD. Give the Folder that contains JSON files.\n",
    "pywalkerMP3('G:\\\\SES\\\\sesq416qna\\\\', 'SES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of sentences: 5595\n",
      "No of emotion readings: 5582\n",
      "5582\n",
      "\n",
      "\n",
      "\n",
      "==================data file updated: ses_data_with_emovec.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "#nq111qna_f000001.mp3\n",
    "def addEmotionVecToJSON(jsonFilePath, emotionFilePath):\n",
    "    data = json.load(open(jsonFilePath))\n",
    "    dataEmo = json.load(open(emotionFilePath))\n",
    "    print \"No of sentences: \" + str(len(data[\"fragments\"]))\n",
    "    print \"No of emotion readings: \" + str(len(dataEmo))\n",
    "    mp3List = []\n",
    "    i = 0\n",
    "    for v in dataEmo:\n",
    "        if v[\"filename\"] not in mp3List:\n",
    "            longfilename = v[\"filename\"]\n",
    "            fname =longfilename[longfilename.find('mp3\\\\')+4:]\n",
    "            for x in data[\"fragments\"]:\n",
    "                fileextract = x[\"sentenceMP3\"]\n",
    "                firstpartfile = fileextract[fileextract.find('qna\\\\')+4:]\n",
    "                idpart = x[\"id\"]\n",
    "                #print 'this? ' + firstpartfile\n",
    "                filenamemp3 = firstpartfile[:-5] + \"_\" + idpart + \".mp3\"\n",
    "                #print 'filename: ' + fname\n",
    "                #print 'filenamemp3: ' + filenamemp3\n",
    "                if fname == filenamemp3:\n",
    "                    i=i+1 \n",
    "                    x[\"elisaEmoVec\"] = v\n",
    "                    #print str(i) + \") \" + filenamemp3 + \" \" + str(v)\n",
    "                    mp3List.append(fname)\n",
    "    print len(mp3List)\n",
    "    #print mp3List[1]\n",
    "    \n",
    "    outFilePath = 'ses_data_with_emovec.json'\n",
    "    with open(outFilePath, 'w') as outfile:\n",
    "        json.dump(data, outfile, sort_keys=True, indent=4)\n",
    "        print \"\\n\\n\\n==================data file updated: \" + outFilePath\n",
    "\n",
    "    return 0\n",
    "\n",
    "addEmotionVecToJSON('SES.json', 'jsn_ses.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of sentences: 5595\n",
      "\n",
      "\n",
      "\n",
      "==================data file updated: demo\\ses_master_calldate.json\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def returnDateFromQuartile(dictionary, quartile, company):\n",
    "    return dict[company.lower() + \"_\" + quartile]\n",
    "\n",
    "dict = {}\n",
    "with open('price_and_position_data\\\\datequartmap.csv', 'rb') as csvfile:\n",
    "    quartmap = csv.reader(csvfile, delimiter=';', quotechar='\"')\n",
    "    for row in quartmap:\n",
    "        dict[row[0].lower() + \"_\" + row[1] ]=row[2]\n",
    "\n",
    "#print returnDateFromQuartile(dict, '20121', 'BT')\n",
    "\n",
    "jsonFilePath = 'demo\\\\ses_master.json'\n",
    "outFilePath = 'demo\\\\ses_master_calldate.json'\n",
    "\n",
    "data = json.load(open(jsonFilePath))\n",
    "print \"No of sentences: \" + str(len(data[\"fragments\"]))\n",
    "i = 0\n",
    "for x in data[\"fragments\"]:\n",
    "    i = i + 1\n",
    "    yearquart = x[\"yearQuartile\"]\n",
    "    comp = x[\"company\"]\n",
    "    x[\"callDate\"] = returnDateFromQuartile(dict, yearquart, comp) \n",
    "\n",
    "with open(outFilePath, 'w') as outfile:\n",
    "    json.dump(data, outfile, sort_keys=True, indent=4)\n",
    "    print \"\\n\\n\\n==================data file updated: \" + outFilePath   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "question_id = \"Nokia.20111.1.0.0\"\n",
    "\n",
    "def sentenceTypeFits(sentenceType, question_id):\n",
    "\treturnVal = False\n",
    "\tanswer_bit = question_id[question_id.rfind(\".\")+1:]\n",
    "\tquestion_bit = question_id[question_id.rfind(\".\", 0, question_id.rfind(\".\"))+1:question_id.rfind(\".\")]\n",
    "\tprint question_bit\n",
    "\tprint answer_bit\n",
    "\t#Q\n",
    "\tif 'Q' in sentenceType and 'A' not in sentenceType and 'O' not in sentenceType: \n",
    "\t\tif question_bit != '0' and answer_bit == '0':\n",
    "\t\t\treturnVal = True\n",
    "\t#A\n",
    "\tif 'Q' not in sentenceType and 'A' in sentenceType and 'O' not in sentenceType: \n",
    "\t\tif answer_bit != '0':\n",
    "\t\t\treturnVal = True\n",
    "\t#O\n",
    "\tif 'Q' not in sentenceType and 'A' not in sentenceType and 'O' in sentenceType: \n",
    "\t\tif question_bit == '0' and answer_bit == '0':\n",
    "\t\t\treturnVal = True\n",
    "\t#QA\n",
    "\tif 'Q' in sentenceType and 'A' in sentenceType and 'O' not in sentenceType: \n",
    "\t\tif question_bit != '0' or answer_bit != '0':\n",
    "\t\t\treturnVal = True\n",
    "\t#QO\n",
    "\tif 'Q' in sentenceType and 'A' not in sentenceType and 'O' in sentenceType: \n",
    "\t\tif answer_bit == '0':\n",
    "\t\t\treturnVal = True\n",
    "\t#AO\n",
    "\tif 'Q' not in sentenceType and 'A' in sentenceType and 'O' in sentenceType: \n",
    "\t\tif question_bit == '0':\n",
    "\t\t\treturnVal = True\n",
    "\t#QAO\n",
    "\tif 'Q' in sentenceType and 'A' in sentenceType and 'O' in sentenceType: \n",
    "\t\treturnVal = True\n",
    "\n",
    "\treturn returnVal\n",
    "\n",
    "print sentenceTypeFits('QA', question_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
